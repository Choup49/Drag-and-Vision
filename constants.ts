
import { Challenge, NodeDefinition, NodeType } from './types';

export const TRANSLATIONS = {
  en: {
    studio: 'Pipeline Studio',
    createNode: 'Create Node',
    challenges: 'Challenges',
    corrector: 'Code Optimizer',
    settings: 'Settings',
    library: 'Node Library',
    export: 'Export Python',
    zoomIn: 'Zoom In',
    zoomOut: 'Zoom Out',
    reset: 'Reset',
    copy: 'Copy to Clipboard',
    generated: 'Generated Python Script',
    noNodes: 'No nodes available',
    back: 'Back',
    start: 'Start Challenge',
    replay: 'Replay Challenge',
    locked: 'Locked',
    consultAI: 'Consult AI',
    aiHint: 'AI Hint',
    objectives: 'Objectives',
    workspace: 'Workspace',
    openWorkspace: 'Open Editor',
    nodeName: 'Node Name',
    nodeLogic: 'Description / Logic',
    generateBtn: 'Generate & Add',
    generating: 'Generating...',
    verify: 'Verify Solution',
    verifying: 'Verifying...',
    success: 'Challenge Completed!',
    fail: 'Keep Trying',
    filterDiff: 'Difficulty',
    all: 'All',
    correctorTitle: 'Code Optimizer',
    correctorDesc: 'Optimize your Computer Vision pipeline with Gemini Intelligence.',
    pasteCode: 'Paste Python Code...',
    analyzeBtn: 'Optimize Code',
    analyzing: 'Optimizing...',
    fixedCode: 'Optimized Code',
    explanation: 'Optimization Report',
    import: 'Import Pipeline',
    importBtn: 'Import',
    saveConfig: 'Save Configuration',
    droidCamConfig: 'DroidCam Setup',
    ipAddress: 'IP Address',
    port: 'Port',
    droidCamHelp: 'Connect your phone using DroidCam IP/Port.',
    fullscreen: 'Fullscreen',
    exitFullscreen: 'Exit Fullscreen',
    createChallenge: 'Create Challenge',
    creatorMode: 'Challenge Creator',
    challengeTitle: 'Title',
    challengeDesc: 'Description',
    challengeObjs: 'Objectives (one per line)',
    saveChallenge: 'Save Challenge',
    filterTheme: 'Theme',
    classTemplate: 'Your logic here',
    genNode: 'AI Node Generator',
    manualMode: 'Manual Implementation',
    descNode: 'Describe what this node should do in plain English.',
    optimize: 'Optimize',
    cppExport: 'C++ Export',
    transpiling: 'Transpiling...',
    transpileBtn: 'Transpile to C++',
    optPreference: 'Optimization Goal',
    speed: 'Max Fluidity (FPS)',
    quality: 'High Accuracy',
    balanced: 'Balanced',
    optDescQuality: 'Prioritizes robust code, error handling, and algorithm accuracy. Slower.',
    optDescSpeed: 'Prioritizes raw execution speed, frame rate, and low latency. Less safe.',
    optDescBalanced: 'A good compromise between detection quality and real-time performance.',
  },
  fr: {
    studio: 'Studio Pipeline',
    createNode: 'Créer un Node',
    challenges: 'Défis',
    corrector: 'Optimiseur de Code',
    settings: 'Paramètres',
    library: 'Bibliothèque',
    export: 'Exporter Python',
    zoomIn: 'Zoomer',
    zoomOut: 'Dézoomer',
    reset: 'Réinitialiser',
    copy: 'Copier',
    generated: 'Script Python Généré',
    noNodes: 'Aucun node disponible',
    back: 'Retour',
    start: 'Lancer le défi',
    replay: 'Rejouer le défi',
    locked: 'Verrouillé',
    consultAI: 'Consulter l\'IA',
    aiHint: 'Indice IA',
    objectives: 'Objectifs',
    workspace: 'Espace de travail',
    openWorkspace: 'Ouvrir l\'Éditeur',
    nodeName: 'Nom du Node',
    nodeLogic: 'Description / Logique',
    generateBtn: 'Générer et Ajouter',
    generating: 'Génération...',
    verify: 'Vérifier la Solution',
    verifying: 'Vérification...',
    success: 'Défi Réussi !',
    fail: 'Essayez encore',
    filterDiff: 'Difficulté',
    all: 'Tous',
    correctorTitle: 'Optimiseur de Code',
    correctorDesc: 'Optimisez votre pipeline Vision avec l\'IA Gemini.',
    pasteCode: 'Collez le code Python...',
    analyzeBtn: 'Optimiser le Code',
    analyzing: 'Optimisation...',
    fixedCode: 'Code Optimisé',
    explanation: 'Rapport d\'Optimisation',
    import: 'Importer Pipeline',
    importBtn: 'Importer',
    saveConfig: 'Sauvegarder Configuration',
    droidCamConfig: 'Configuration DroidCam',
    ipAddress: 'Adresse IP',
    port: 'Port',
    droidCamHelp: 'Connectez votre téléphone via l\'IP/Port de DroidCam.',
    fullscreen: 'Plein Écran',
    exitFullscreen: 'Quitter Plein Écran',
    createChallenge: 'Créer un Défi',
    creatorMode: 'Créateur de Défis',
    challengeTitle: 'Titre',
    challengeDesc: 'Description',
    challengeObjs: 'Objectifs (un par ligne)',
    saveChallenge: 'Sauvegarder le Défi',
    filterTheme: 'Thème',
    classTemplate: 'Votre logique ici',
    genNode: 'Générateur de Node IA',
    manualMode: 'Implémentation Manuelle',
    descNode: 'Décrivez ce que ce node doit faire.',
    optimize: 'Optimiser',
    cppExport: 'Export C++',
    transpiling: 'Transpilation...',
    transpileBtn: 'Transpiler en C++',
    optPreference: 'Objectif d\'Optimisation',
    speed: 'Fluidité Max (FPS)',
    quality: 'Haute Précision',
    balanced: 'Équilibré',
    optDescQuality: 'Priorise la robustesse, la gestion d\'erreurs et la précision. Plus lent.',
    optDescSpeed: 'Priorise la vitesse d\'exécution brute, les FPS et la latence. Moins sûr.',
    optDescBalanced: 'Un bon compromis entre qualité de détection et performance temps réel.',
  }
};

export const AVAILABLE_NODES: NodeDefinition[] = [
  // --- CORE / SOURCES ---
  { 
    id: 'src_webcam', 
    name: 'Webcam Feed', 
    name_fr: 'Flux Webcam',
    type: NodeType.SOURCE, 
    description: 'Capture from default camera', 
    description_fr: 'Capture depuis la caméra par défaut',
    category: 'input',
    library: 'Core',
    pythonClass: 'cv2.VideoCapture',
    pythonTemplate: `# Setup\ncap = cv2.VideoCapture(0)\n# Process\nret, {output} = cap.read()\nif not ret: break`,
    requiredImports: ['cv2'],
    inputs: 0,
    outputs: 1
  },
  { 
    id: 'src_droidcam', 
    name: 'DroidCam', 
    name_fr: 'DroidCam',
    type: NodeType.SOURCE, 
    description: 'Connect via IP/Wifi', 
    description_fr: 'Connecter via IP/Wifi',
    category: 'input',
    library: 'Core',
    pythonClass: 'cv2.VideoCapture',
    pythonTemplate: `# Setup\ncap = cv2.VideoCapture("http://{ip}:{port}/video")\n# Process\nret, {output} = cap.read()\nif not ret: break`,
    requiredImports: ['cv2'],
    inputs: 0,
    outputs: 1
  },

  // --- OPENCV TRANSFORMS ---
  {
    id: 'cv_gray',
    name: 'Grayscale',
    name_fr: 'Niveau de Gris',
    type: NodeType.PROCESS,
    description: 'Convert image to grayscale',
    description_fr: 'Convertir en niveaux de gris',
    category: 'transform',
    library: 'OpenCV',
    pythonClass: 'cv2.cvtColor',
    pythonTemplate: `{output} = cv2.cvtColor({input}, cv2.COLOR_BGR2GRAY)`,
    requiredImports: ['cv2'],
    inputs: 1,
    outputs: 1
  },
  {
    id: 'cv_blur',
    name: 'Gaussian Blur',
    name_fr: 'Flou Gaussien',
    type: NodeType.PROCESS,
    description: 'Apply soft blur filter',
    description_fr: 'Appliquer un flou doux',
    category: 'transform',
    library: 'OpenCV',
    pythonClass: 'cv2.GaussianBlur',
    pythonTemplate: `{output} = cv2.GaussianBlur({input}, (5, 5), 0)`,
    requiredImports: ['cv2'],
    inputs: 1,
    outputs: 1
  },
  {
    id: 'cv_canny',
    name: 'Canny Edges',
    name_fr: 'Contours Canny',
    type: NodeType.PROCESS,
    description: 'Detect object boundaries',
    description_fr: 'Détecter les contours',
    category: 'transform',
    library: 'OpenCV',
    pythonClass: 'cv2.Canny',
    pythonTemplate: `{output} = cv2.Canny({input}, 100, 200)`,
    requiredImports: ['cv2'],
    inputs: 1,
    outputs: 1
  },
  {
    id: 'cv_flip',
    name: 'Mirror Flip',
    name_fr: 'Effet Miroir',
    type: NodeType.PROCESS,
    description: 'Flip image horizontally',
    description_fr: 'Retourner horizontalement',
    category: 'transform',
    library: 'OpenCV',
    pythonClass: 'cv2.flip',
    pythonTemplate: `{output} = cv2.flip({input}, 1)`,
    requiredImports: ['cv2'],
    inputs: 1,
    outputs: 1
  },
  {
    id: 'cv_thresh',
    name: 'Threshold',
    name_fr: 'Seuillage',
    type: NodeType.PROCESS,
    description: 'Binary thresholding (Black/White)',
    description_fr: 'Seuillage binaire (Noir/Blanc)',
    category: 'transform',
    library: 'OpenCV',
    pythonClass: 'cv2.threshold',
    pythonTemplate: `_, {output} = cv2.threshold({input}, 127, 255, cv2.THRESH_BINARY)`,
    requiredImports: ['cv2'],
    inputs: 1,
    outputs: 1
  },
  {
    id: 'cv_hsv',
    name: 'HSV Space',
    name_fr: 'Espace HSV',
    type: NodeType.PROCESS,
    description: 'Convert BGR to HSV',
    description_fr: 'Convertir BGR vers HSV',
    category: 'transform',
    library: 'OpenCV',
    pythonClass: 'cv2.cvtColor',
    pythonTemplate: `{output} = cv2.cvtColor({input}, cv2.COLOR_BGR2HSV)`,
    requiredImports: ['cv2'],
    inputs: 1,
    outputs: 1
  },

  // --- MEDIAPIPE AI ---
  {
    id: 'mp_hands',
    name: 'Hand Tracking',
    name_fr: 'Suivi des Mains',
    type: NodeType.AI,
    description: 'MediaPipe Hand Landmark Detection',
    description_fr: 'Détection des mains avec MediaPipe',
    category: 'ai',
    library: 'MediaPipe',
    pythonClass: 'mp.solutions.hands',
    pythonTemplate: `# Setup\nimport mediapipe as mp\nmp_hands = mp.solutions.hands\nhands = mp_hands.Hands()\nmp_draw = mp.solutions.drawing_utils\n# Process\n{output} = {input}.copy()\nres = hands.process(cv2.cvtColor({input}, cv2.COLOR_BGR2RGB))\nif res.multi_hand_landmarks:\n    for lms in res.multi_hand_landmarks: mp_draw.draw_landmarks({output}, lms, mp_hands.HAND_CONNECTIONS)`,
    requiredImports: ['cv2', 'mediapipe as mp'],
    inputs: 1,
    outputs: 1
  },
  {
    id: 'mp_face_detection',
    name: 'Face Detection',
    name_fr: 'Détection Visage',
    type: NodeType.AI,
    description: 'Detect face bounding box',
    description_fr: 'Détecter le cadre du visage',
    category: 'ai',
    library: 'MediaPipe',
    pythonClass: 'mp.solutions.face_detection',
    pythonTemplate: `# Setup\nimport mediapipe as mp\nmp_face = mp.solutions.face_detection\nface_det = mp_face.FaceDetection()\nmp_draw = mp.solutions.drawing_utils\n# Process\n{output} = {input}.copy()\nres = face_det.process(cv2.cvtColor({input}, cv2.COLOR_BGR2RGB))\nif res.detections:\n    for det in res.detections: mp_draw.draw_detection({output}, det)`,
    requiredImports: ['cv2', 'mediapipe as mp'],
    inputs: 1,
    outputs: 1
  },
  {
    id: 'mp_pose',
    name: 'Pose Estimation',
    name_fr: 'Estimation de Pose',
    type: NodeType.AI,
    description: 'Full body tracking',
    description_fr: 'Suivi corporel complet',
    category: 'ai',
    library: 'MediaPipe',
    pythonClass: 'mp.solutions.pose',
    pythonTemplate: `# Setup\nimport mediapipe as mp\nmp_pose = mp.solutions.pose\npose = mp_pose.Pose()\nmp_draw = mp.solutions.drawing_utils\n# Process\n{output} = {input}.copy()\nres = pose.process(cv2.cvtColor({input}, cv2.COLOR_BGR2RGB))\nif res.pose_landmarks: mp_draw.draw_landmarks({output}, res.pose_landmarks, mp_pose.POSE_CONNECTIONS)`,
    requiredImports: ['cv2', 'mediapipe as mp'],
    inputs: 1,
    outputs: 1
  },
  {
    id: 'mp_face_mesh',
    name: 'Face Mesh',
    name_fr: 'Maillage Facial',
    type: NodeType.AI,
    description: 'High fidelity face tracking',
    description_fr: 'Suivi facial haute précision',
    category: 'ai',
    library: 'MediaPipe',
    pythonClass: 'mp.solutions.face_mesh',
    pythonTemplate: `# Setup\nimport mediapipe as mp\nmp_mesh = mp.solutions.face_mesh\nface_mesh = mp_mesh.FaceMesh()\nmp_draw = mp.solutions.drawing_utils\n# Process\n{output} = {input}.copy()\nres = face_mesh.process(cv2.cvtColor({input}, cv2.COLOR_BGR2RGB))\nif res.multi_face_landmarks:\n    for lms in res.multi_face_landmarks: mp_draw.draw_landmarks({output}, lms, mp_mesh.FACEMESH_CONTOURS)`,
    requiredImports: ['cv2', 'mediapipe as mp'],
    inputs: 1,
    outputs: 1
  },
  { 
    id: 'out_screen', 
    name: 'Display', 
    name_fr: 'Affichage',
    type: NodeType.OUTPUT, 
    description: 'Show result in window', 
    description_fr: 'Afficher dans une fenêtre',
    category: 'output',
    library: 'Core',
    pythonClass: 'cv2.imshow',
    pythonTemplate: `cv2.imshow("PyVision Output", {input})`,
    requiredImports: ['cv2'],
    inputs: 1,
    outputs: 0
  }
];

export const CHALLENGES: Challenge[] = [
  // --- THEME: BASIC ---
  {
    id: 'ch_basic_easy',
    title: 'Classic Noir',
    title_fr: 'Classique Noir',
    difficulty: 'Easy',
    theme: 'Basic',
    description: 'Create a simple black and white live feed using the Grayscale node.',
    description_fr: 'Créez un flux vidéo noir et blanc simple avec le node Niveau de Gris.',
    objectives: ['Webcam -> Grayscale -> Display'],
    objectives_fr: ['Webcam -> Niveau de Gris -> Affichage'],
    locked: false
  },
  {
    id: 'ch_basic_normal',
    title: 'Neon Outlines',
    title_fr: 'Contours Néon',
    difficulty: 'Normal',
    theme: 'Basic',
    description: 'Detect edges to create a glowing neon effect on the video feed.',
    description_fr: 'Détectez les bords pour créer un effet néon sur le flux vidéo.',
    objectives: ['Webcam -> Canny Edges -> Display'],
    objectives_fr: ['Webcam -> Contours Canny -> Affichage'],
    locked: false
  },
  {
    id: 'ch_basic_hard',
    title: 'Ghost Mode',
    title_fr: 'Mode Fantôme',
    difficulty: 'Hard',
    theme: 'Basic',
    description: 'Combine blurring and flipping to create a disorienting ghost effect.',
    description_fr: 'Combinez flou et retournement pour créer un effet fantôme désorientant.',
    objectives: ['Webcam -> Blur -> Mirror Flip -> Display'],
    objectives_fr: ['Webcam -> Flou -> Miroir -> Affichage'],
    locked: false
  },

  // --- THEME: TRACKING ---
  {
    id: 'ch_track_easy',
    title: 'Face Box',
    title_fr: 'Boîte Visage',
    difficulty: 'Easy',
    theme: 'Tracking',
    description: 'Use MediaPipe to detect faces and draw a bounding box around them.',
    description_fr: 'Utilisez MediaPipe pour détecter les visages et dessiner un cadre autour.',
    objectives: ['Webcam -> Face Detection -> Display'],
    objectives_fr: ['Webcam -> Détection Visage -> Affichage'],
    locked: false
  },
  {
    id: 'ch_track_normal',
    title: 'Hand Skeleton',
    title_fr: 'Squelette Main',
    difficulty: 'Normal',
    theme: 'Tracking',
    description: 'Track the skeletal landmarks of your hands in real-time.',
    description_fr: 'Suivez les repères squelettiques de vos mains en temps réel.',
    objectives: ['Webcam -> Hand Tracking -> Display'],
    objectives_fr: ['Webcam -> Suivi Mains -> Affichage'],
    locked: false
  },
  {
    id: 'ch_track_hard',
    title: 'Full Body Mesh',
    title_fr: 'Maillage Corporel',
    difficulty: 'Hard',
    theme: 'Tracking',
    description: 'Perform complex full-body pose estimation to map the entire human skeleton.',
    description_fr: 'Effectuez une estimation de pose complète pour cartographier tout le squelette.',
    objectives: ['Webcam -> Pose Estimation -> Display'],
    objectives_fr: ['Webcam -> Estimation Pose -> Affichage'],
    locked: false
  },

  // --- THEME: SEGMENTATION ---
  {
    id: 'ch_seg_easy',
    title: 'Binary World',
    title_fr: 'Monde Binaire',
    difficulty: 'Easy',
    theme: 'Segmentation',
    description: 'Reduce the complex world to black and white pixels using thresholding.',
    description_fr: 'Réduisez le monde complexe à des pixels noirs et blancs via le seuillage.',
    objectives: ['Webcam -> Grayscale -> Threshold -> Display'],
    objectives_fr: ['Webcam -> Gris -> Seuillage -> Affichage'],
    locked: false
  },
  {
    id: 'ch_seg_normal',
    title: 'Privacy Filter',
    title_fr: 'Filtre Privé',
    difficulty: 'Normal',
    theme: 'Segmentation',
    description: 'Apply a heavy blur to the entire image to simulate privacy protection.',
    description_fr: 'Appliquez un flou important à toute l\'image pour simuler la confidentialité.',
    objectives: ['Webcam -> Gaussian Blur -> Display'],
    objectives_fr: ['Webcam -> Flou Gaussien -> Affichage'],
    locked: false
  },
  {
    id: 'ch_seg_hard',
    title: 'Color Map',
    title_fr: 'Carte de Couleur',
    difficulty: 'Hard',
    theme: 'Segmentation',
    description: 'Convert the image to HSV space to visualize color segmentation channels.',
    description_fr: 'Convertissez l\'image en espace HSV pour visualiser les canaux de couleur.',
    objectives: ['Webcam -> HSV Space -> Display'],
    objectives_fr: ['Webcam -> Espace HSV -> Affichage'],
    locked: false
  },

  // --- THEME: CREATIVE ---
  {
    id: 'ch_create_easy',
    title: 'Mirror Mirror',
    title_fr: 'Miroir Miroir',
    difficulty: 'Easy',
    theme: 'Creative',
    description: 'Simple mirror effect to correct the webcam feed orientation.',
    description_fr: 'Effet miroir simple pour corriger l\'orientation de la webcam.',
    objectives: ['Webcam -> Mirror Flip -> Display'],
    objectives_fr: ['Webcam -> Miroir -> Affichage'],
    locked: false
  },
  {
    id: 'ch_create_normal',
    title: 'Artistic Blur',
    title_fr: 'Flou Artistique',
    difficulty: 'Normal',
    theme: 'Creative',
    description: 'Combine blurring with edge detection for a sketch-like effect.',
    description_fr: 'Combinez flou et détection de contours pour un effet croquis.',
    objectives: ['Webcam -> Gaussian Blur -> Canny Edges -> Display'],
    objectives_fr: ['Webcam -> Flou -> Contours Canny -> Affichage'],
    locked: false
  },
  {
    id: 'ch_create_hard',
    title: 'Abstract Hands',
    title_fr: 'Mains Abstraites',
    difficulty: 'Hard',
    theme: 'Creative',
    description: 'Flip the world and track hands in reverse for a mind-bending experience.',
    description_fr: 'Retournez le monde et suivez les mains à l\'envers pour une expérience troublante.',
    objectives: ['Webcam -> Mirror Flip -> Hand Tracking -> Display'],
    objectives_fr: ['Webcam -> Miroir -> Suivi Mains -> Affichage'],
    locked: false
  }
];
